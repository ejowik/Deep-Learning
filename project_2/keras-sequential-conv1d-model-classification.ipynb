{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "6e7b6f6347f596f78b3a8fb88cb7a820541998b1"
   },
   "outputs": [],
   "source": [
    "#path\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific Math \n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#Deep learning\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "bb0bfbe942e8dc8e6bf4864b7ec66212734657bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1979ce525c49d97564617560c48fe00e40707b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero', '_background_noise_']\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = './data/train/audio/'\n",
    "print(os.listdir(train_audio_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc717705d62e8a2a312a983f59ab0406c0e0329b"
   },
   "source": [
    "### Load Data\n",
    "\n",
    "target list is ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "unknown list is other\n",
    "silence will be made from '_background_noise_'\n",
    "\n",
    "Train data's sampling rate is 16000Hz, but for making lower computation cost, Resample to 8000hz\n",
    "\n",
    "After training, test set also will resample to 8000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "baf56ce3fd56eb7c6dd4b5d088105a631654071e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 30\n",
      "['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path, f))]\n",
    "dirs.sort()\n",
    "print('Number of labels: ' + str(len(dirs[1:])))\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "cdeb5698a33395d714bd7ec249f25a668734bc7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_list : ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
      "unknowns_list : ['bed', 'bird', 'cat', 'dog', 'eight', 'five', 'four', 'happy', 'house', 'marvin', 'nine', 'one', 'seven', 'sheila', 'six', 'three', 'tree', 'two', 'wow', 'zero']\n",
      "silence : _background_noise_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agama\\AppData\\Local\\Temp\\ipykernel_9812\\1046369037.py:17: FutureWarning:\n",
      "\n",
      "Pass orig_sr=22050, target_sr=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:bed "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agama\\AppData\\Local\\Temp\\ipykernel_9812\\1046369037.py:27: FutureWarning:\n",
      "\n",
      "Pass orig_sr=16000, target_sr=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:bird 3:cat 4:dog 5:down 6:eight 7:five 8:four 9:go "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_wav = []\n",
    "unknown_wav = []\n",
    "label_all = []\n",
    "label_value = {}\n",
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "unknown_list = [d for d in dirs if d not in target_list and d != '_background_noise_' ]\n",
    "print('target_list : ',end='')\n",
    "print(target_list)\n",
    "print('unknowns_list : ', end='')\n",
    "print(unknown_list)\n",
    "print('silence : _background_noise_')\n",
    "i=0;\n",
    "background = [f for f in os.listdir(join(train_audio_path, '_background_noise_')) if f.endswith('.wav')]\n",
    "background_noise = []\n",
    "for wav in background : \n",
    "    samples, sample_rate = librosa.load(join(join(train_audio_path,'_background_noise_'),wav))\n",
    "    samples = librosa.resample(samples, sample_rate, 8000)\n",
    "    background_noise.append(samples)\n",
    "\n",
    "for direct in dirs[1:]:\n",
    "    waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
    "    label_value[direct] = i\n",
    "    i = i + 1\n",
    "    print(str(i)+\":\" +str(direct) + \" \", end=\"\")\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(join(join(train_audio_path,direct),wav), sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if len(samples) != 8000 : \n",
    "            continue\n",
    "            \n",
    "        if direct in unknown_list:\n",
    "            unknown_wav.append(samples)\n",
    "        else:\n",
    "            label_all.append(direct)\n",
    "            all_wav.append([samples, direct])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9efa60ca094eeae08d34e078d4ec62231e50054"
   },
   "source": [
    "split wav, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8501a2e50843829e3a51853c683f105b040e954f"
   },
   "outputs": [],
   "source": [
    "wav_all = np.reshape(np.delete(all_wav,1,1),(len(all_wav)))\n",
    "label_all = [i for i in np.delete(all_wav,0,1).tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3239651e24e6decb63e5c5c9221650357d684c2"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For Data Augmentation. I will mix train wav, and same length(1 sec) noise(10%) from '_background_noise_'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b59088b2bb5dc1848246dd4320d134ac0c673e65"
   },
   "outputs": [],
   "source": [
    "#Random pick start point\n",
    "def get_one_noise(noise_num = 0):\n",
    "    selected_noise = background_noise[noise_num]\n",
    "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
    "    return selected_noise[start_idx:(start_idx + 8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "073bc68512dc809aff793dc03dc380d570631457"
   },
   "outputs": [],
   "source": [
    "max_ratio = 0.1\n",
    "noised_wav = []\n",
    "augment = 1\n",
    "delete_index = []\n",
    "for i in range(augment):\n",
    "    new_wav = []\n",
    "    noise = get_one_noise(i)\n",
    "    for i, s in enumerate(wav_all):\n",
    "        if len(s) != 8000:\n",
    "            delete_index.append(i)\n",
    "            continue\n",
    "        s = s + (max_ratio * noise)\n",
    "        noised_wav.append(s)\n",
    "np.delete(wav_all, delete_index)\n",
    "np.delete(label_all, delete_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6bd94ec47be96cba4be12c60b91ed90044aedea0"
   },
   "outputs": [],
   "source": [
    "wav_vals = np.array([x for x in wav_all])\n",
    "label_vals = [x for x in label_all]\n",
    "wav_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94ef3d33c62e27cb1fb53a29025c010ec56ffbb4"
   },
   "outputs": [],
   "source": [
    "labels = copy.deepcopy(label_vals)\n",
    "for _ in range(augment):\n",
    "    label_vals = np.concatenate((label_vals, labels), axis = 0)\n",
    "label_vals = label_vals.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e20c12d950b7ff2e8904fc57d5a9d429cd4b130d"
   },
   "source": [
    "Random sampling from unknown wav data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ee0b02d7cfbcc02ea20d65ee268ba44e01bf2b1"
   },
   "outputs": [],
   "source": [
    "#knowns audio random sampling\n",
    "unknown = unknown_wav\n",
    "np.random.shuffle(unknown_wav)\n",
    "unknown = np.array(unknown)\n",
    "unknown = unknown[:2000*(augment+1)]\n",
    "unknown_label = np.array(['unknown' for _ in range(2000*(augment+1))])\n",
    "unknown_label = unknown_label.reshape(2000*(augment+1),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72a6f2c8663ee74708da42313ed2e8d24c832b3f"
   },
   "source": [
    "May Some wav data has different length. So, Delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70a499bce28fd081b7fa9742eb03851ebe4eb5f1"
   },
   "outputs": [],
   "source": [
    "delete_index = []\n",
    "for i,w in enumerate(unknown):\n",
    "    if len(w) != 8000:\n",
    "        delete_index.append(i)\n",
    "unknown = np.delete(unknown, delete_index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a1f8bf0426f373ed063df7f1adbd963943a3fd0"
   },
   "source": [
    "Random sampling from '_background_noise_' \n",
    "\n",
    "Random pick background noise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ef23bb8580b70f2b52e2d91fb183674112d2eba"
   },
   "outputs": [],
   "source": [
    "#silence audio\n",
    "silence_wav = []\n",
    "num_wav = (2000*(augment+1))//len(background_noise)\n",
    "for i, _ in enumerate(background_noise):\n",
    "    for _ in range((2000*(augment+1))//len(background_noise)):\n",
    "        silence_wav.append(get_one_noise(i))\n",
    "silence_wav = np.array(silence_wav)\n",
    "silence_label = np.array(['silence' for _ in range(num_wav*len(background_noise))])\n",
    "silence_label = silence_label.reshape(-1,1)\n",
    "silence_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c06ab04ada253e19a0207d280ed3c1a444776cd3"
   },
   "outputs": [],
   "source": [
    "wav_vals    = np.reshape(wav_vals,    (-1, 8000))\n",
    "noised_wav  = np.reshape(noised_wav,  (-1, 8000))\n",
    "unknown       = np.reshape(unknown,   (-1, 8000))\n",
    "silence_wav = np.reshape(silence_wav, (-1, 8000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e1666c5bf721dbf9e4717be0d469734db9182f2"
   },
   "source": [
    "Check Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "841b9a9b2a2c38297a7a6d1c93744965755703fa"
   },
   "outputs": [],
   "source": [
    "print(wav_vals.shape)\n",
    "print(noised_wav.shape)\n",
    "print(unknown.shape)\n",
    "print(silence_wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab1aba8c05398669f6e3152d74e00e8a41ee7503"
   },
   "outputs": [],
   "source": [
    "print(label_vals.shape)\n",
    "print(unknown_label.shape)\n",
    "print(silence_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6816376d4450daffeb79114df92d3fb0eafb59a"
   },
   "source": [
    "Concatenate wavs, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d6afa30a5dda2b9ca4888b36aabe5b89922a121"
   },
   "outputs": [],
   "source": [
    "wav_vals = np.concatenate((wav_vals, noised_wav), axis = 0)\n",
    "wav_vals = np.concatenate((wav_vals, unknown), axis = 0)\n",
    "wav_vals = np.concatenate((wav_vals, silence_wav), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "420f9d709f805349b2635a80dabc383595eac011"
   },
   "outputs": [],
   "source": [
    "label_vals = np.concatenate((label_vals, unknown_label), axis = 0)\n",
    "label_vals = np.concatenate((label_vals, silence_label), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c33c9dc3fe0daa57968e89fa6c22352a8b53f55"
   },
   "outputs": [],
   "source": [
    "print(len(wav_vals))\n",
    "print(len(label_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63c2da5df2edd06ab1fbdf6c1a50ad02216f0fe5"
   },
   "source": [
    "### Prepare Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba0ab85ffd216b4d91855ea234b3202ba250b8be"
   },
   "outputs": [],
   "source": [
    "train_wav, test_wav, train_label, test_label = train_test_split(wav_vals, label_vals, \n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state = 1993,\n",
    "                                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e6a9e72fbee7fd3bf612e60d5709b177deacaec"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 512\n",
    "drop_out_rate = 0.5\n",
    "input_shape = (8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73ffc6cf54f2100c1aa47203f0c33e350198dc3d"
   },
   "outputs": [],
   "source": [
    "#For Conv1D add Channel\n",
    "train_wav = train_wav.reshape(-1,8000,1)\n",
    "test_wav = test_wav.reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75fd1a40241009a857b5db9c878c9c665bdc84f2"
   },
   "outputs": [],
   "source": [
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb801f97812407f60af16a787a0ae01db8e88038"
   },
   "outputs": [],
   "source": [
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "label_value = new_label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65647981d409fb31ac391af3d5d091ef354a0f02"
   },
   "outputs": [],
   "source": [
    "#Make Label data 'string' -> 'class num'\n",
    "temp = []\n",
    "for v in train_label:\n",
    "    temp.append(label_value[v[0]])\n",
    "train_label = np.array(temp)\n",
    "\n",
    "temp = []\n",
    "for v in test_label:\n",
    "    temp.append(label_value[v[0]])\n",
    "test_label = np.array(temp)\n",
    "\n",
    "#Make Label data 'class num' -> 'One hot vector'\n",
    "train_label = keras.utils.to_categorical(train_label, len(label_value))\n",
    "test_label = keras.utils.to_categorical(test_label, len(label_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96b340a033294465394c168e232df012a011ae1a"
   },
   "outputs": [],
   "source": [
    "print('Train_Wav Demension : ' + str(np.shape(train_wav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "994265f130050666438cd7a14357ef766b279495",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train_Label Demension : ' + str(np.shape(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edf649f1ec18a201a7a2b2bf9c5115e443fe6b03"
   },
   "outputs": [],
   "source": [
    "print('Test_Wav Demension : ' + str(np.shape(test_wav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3bf3f485f3b3f4e44f25ce4ec35861a7b22f866"
   },
   "outputs": [],
   "source": [
    "print('Test_Label Demension : ' + str(np.shape(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "557d3f766acfe47197813f0301d0b562cf3388be"
   },
   "outputs": [],
   "source": [
    "print('Number Of Labels : ' + str(len(label_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3ac90355cbf04993a8b090483164d0e86401855"
   },
   "outputs": [],
   "source": [
    "#Conv1D Model\n",
    "input_tensor = Input(shape=(input_shape))\n",
    "\n",
    "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Conv1D(128, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(len(label_value), activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = lr),\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c1c50793d9d2c12af1cbf1029daca221afdaff9"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45ce60c3949727441c5c75dabb3575cb95aa59be"
   },
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b61710f92afdf22a09a07b9dd9d3ddc3e75c05b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_wav, train_label, validation_data=[test_wav, test_label],\n",
    "          batch_size=batch_size, \n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cbb0f06ea603cb0e5ef7b9893080ecfdd082864"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
