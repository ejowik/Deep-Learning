{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd903cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:41.935728Z",
     "start_time": "2022-05-03T19:18:42.624305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 09:17:16.871664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-05 09:17:16.871686: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from itertools import compress\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import keras\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Bidirectional, Conv1D, GRU\n",
    "from tensorflow.keras.layers import Input, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "random.seed(0)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = 9,6\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c98eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:41.953344Z",
     "start_time": "2022-05-03T19:19:41.940535Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters settings\n",
    "data_path = './../data/train/audio'\n",
    "labels = os.listdir(data_path)\n",
    "CLASSES = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go'] \n",
    "SAMPLING_RATE = 16000\n",
    "NOISE_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1846a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:41.977535Z",
     "start_time": "2022-05-03T19:19:41.957550Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples):\n",
    "    return np.pad(samples, pad_width=(SAMPLING_RATE - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "\n",
    "def chop_audio(samples):\n",
    "    return samples[:SAMPLING_RATE]\n",
    "\n",
    "\n",
    "def split_audio(sample_rate, samples):\n",
    "    \"\"\" Splits audio file to multiple with (up to) fixed 1s length \"\"\"\n",
    "    duration = float(len(samples)/sample_rate)\n",
    "    n_samples = math.ceil(duration)\n",
    "    return np.array_split(samples, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f417dec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:41.986466Z",
     "start_time": "2022-05-03T19:19:41.979519Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_unknown_label(labels, classes=CLASSES):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            new_labels.append('unknown')\n",
    "        else:\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def encode_labels(labels):\n",
    "    return pd.get_dummies(pd.Series(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5733564b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:42.010772Z",
     "start_time": "2022-05-03T19:19:41.988447Z"
    }
   },
   "outputs": [],
   "source": [
    "def specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    _, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "\n",
    "def plot_model_history(history, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plotting the learning curve of Keras model, broken down into loss curve and accuracy curve, \n",
    "    for both training and validation data.\n",
    "\n",
    "    Args:\n",
    "        history : Object returned by the .fit method of Keras model.\n",
    "        title (str): Title of the plots.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    fig.suptitle(title, size=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46539ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:42.029737Z",
     "start_time": "2022-05-03T19:19:42.012906Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_network(input_dim, output_dim, rnn_layer, optimizer):\n",
    "\n",
    "    input_data = Input(name='input', shape=input_dim, dtype='float32')\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=10, strides=4, name='conv1d')(input_data)\n",
    "    x = BatchNormalization(name='b_norm')(x)\n",
    "    x = Activation('relu', name='activation')(x)\n",
    "    x = Dropout(DROPOUT, name='dropout_1')(x)\n",
    "#     x = rnn_layer(128, activation='relu', return_sequences=True, dropout=DROPOUT, name='rnn_1')(x)\n",
    "    x = rnn_layer(128, activation='relu', return_sequences=False, dropout=DROPOUT, name='rnn_1')(x)\n",
    "    x = Dense(units=64, activation='relu', name='dense')(x)\n",
    "    x = Dropout(DROPOUT, name='dropout_2')(x)\n",
    "\n",
    "    output_data = Dense(units=output_dim, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_data, name=str(rnn_layer).split(\".\")[-1].split(\"'\")[0])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a196fc1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:42.055156Z",
     "start_time": "2022-05-03T19:19:42.031955Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmaps(models_results: list, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot heatmaps based on the confusion matrices of given models.\n",
    "\n",
    "    Args:\n",
    "        models_results (list): List of confusion matrices of the evaluated models.\n",
    "        title (str): Title of the plots.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1,3,figsize=(18,6))\n",
    "    models = ['SimpleRNN', 'LSTM', 'GRU']\n",
    "    for i in range(3):\n",
    "        sns.heatmap(models_results[i], center=0.5, annot=True, cmap=\"coolwarm\", linewidths=1, linecolor='black', ax=axes[i], annot_kws={\"size\": 12})\n",
    "        axes[i].set_title(models[i], size=15)\n",
    "        cax = plt.gcf().axes[-1]\n",
    "        cax.tick_params(labelsize=12)\n",
    "\n",
    "    fig.suptitle(title, size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matr(models_results: list, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot heatmaps based on the confusion matrices of given models.\n",
    "\n",
    "    Args:\n",
    "        models_results (list): List of confusion matrices of the evaluated models.\n",
    "        title (str): Title of the plots.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1,3,figsize=(18,6))\n",
    "    models = ['SimpleRNN', 'LSTM', 'GRU']\n",
    "    for i in range(3):\n",
    "        sns.heatmap(models_results[i], annot=True, cmap=\"Blues\", linewidths=1, linecolor='black', ax=axes[i], fmt='d', annot_kws={\"size\": 12})\n",
    "        axes[i].set_title(models[i], size=15)\n",
    "        axes[i].set_xticklabels(axes[i].get_xmajorticklabels(), fontsize = 12)\n",
    "        axes[i].set_yticklabels(axes[i].get_xmajorticklabels(), fontsize = 12)\n",
    "        cax = plt.gcf().axes[-1]\n",
    "        cax.tick_params(labelsize=12)\n",
    "\n",
    "    fig.suptitle(title, size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72d5e9",
   "metadata": {},
   "source": [
    "# <span style='font-family:Georgia'> 1. Data loading & preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3636c",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> 1.1. Noisy data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb8c4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:43.194386Z",
     "start_time": "2022-05-03T19:19:42.059166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8791f7f51c814685bafe477f04a30308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = '_background_noise_'\n",
    "files = [f for f in os.listdir(data_path + '/'+ label) if f.endswith('.wav')]\n",
    "one_sec_background_noise_specgrams = []\n",
    "\n",
    "for file in tqdm(files):\n",
    "    _, samples = wavfile.read(data_path + \"/\" + label + \"/\" + file)\n",
    "    duration = float(len(samples)/SAMPLING_RATE)\n",
    "\n",
    "    # Do not distinguish between noise classes\n",
    "    one_sec_background_noise = split_audio(\n",
    "            sample_rate=SAMPLING_RATE, samples=samples\n",
    "        )\n",
    "    \n",
    "    for item in one_sec_background_noise:\n",
    "        duration = float(len(item)/SAMPLING_RATE)\n",
    "        if duration < 1: item = pad_audio(item)        \n",
    "        \n",
    "        one_sec_background_noise_specgrams.append(\n",
    "            specgram(item, SAMPLING_RATE)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6aec04",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> 1.2. Noise-free data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec2f8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:43.253189Z",
     "start_time": "2022-05-03T19:19:43.198723Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_list = pd.read_csv('./../data/train/validation_list.txt', sep=\"\\t\", header=None)[0].tolist()\n",
    "testing_list = pd.read_csv('./../data/train/testing_list.txt', sep=\"\\t\", header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c70ae40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:19:43.276754Z",
     "start_time": "2022-05-03T19:19:43.255173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  51088\n",
      "Validation:  6798\n",
      "Testing:  6835\n"
     ]
    }
   ],
   "source": [
    "print('Training: ', 64721 - len(validation_list) - len(testing_list))\n",
    "print('Validation: ', len(validation_list))\n",
    "print('Testing: ', len(testing_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006bce66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:00.606450Z",
     "start_time": "2022-05-03T19:19:43.279701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2196c96c1c44c9b941a2feac7bbe3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa06e12e3dc3444fa0969085506dc7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b771d686760e4b1e8681db509e2c6411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06474cf2022c4c55938a01dfa3e8e1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98415565127e4d73acbf5c0f9310da08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1947298c724dfc8c6193dfdfb31a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9219d60e12904acdab0976a670477170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17986a90048b4c86a8e6f98c9f4562a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b1727e76e845a0b32b220799a63120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1731 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209191aa5f6143628ed9f83133de7a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d17ad8c616f451eb8e2bf3ca3e93aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed7afd903234949b30986b708fdb062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e5822fefd94e99b091dd629f7a0fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916ad97e5527464887dbaefb2e704dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b33cf60a45741e5833851a2947c449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543faa023c554a5a8dbb4ea2c973e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3807c90ba1734afbb15f0102deb22c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d4614905694150ab3d2c2dbbdff262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b9f3ae9df14f5f8b43fea2a7fed390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f597cc73ac44b21896a5c05ffb4282e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807ebb8331674328a0cfbfdcf13f7bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a925a83ed3e64dd1a126a3fbdc2a22fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14c41551c7044218bb7b5a278e0bfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e8f646808497ea4562d364c12bf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10451c0f6e144ca9c438d8e0ed0c9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97060025fe54ec5a7b3820c7c7171a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3792cceff5a84caaab8e1a1d0ce1d933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c84120187ef4b8daea38b2cc837b56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1742 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbc8ea4cc9a4efc95f2c4edd3cd4697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4e21ccc0074a83b0ca32b331939113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c5daca56674a22b9cc77ff324d78e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels = []\n",
    "train_specgrams = []\n",
    "val_labels = []\n",
    "val_specgrams = []\n",
    "test_labels = []\n",
    "test_specgrams = []\n",
    "\n",
    "for label in tqdm([l for l in labels if l != '_background_noise_']):\n",
    "\n",
    "    files = [f for f in os.listdir(data_path + '/'+ label) if f.endswith('.wav')]\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        _, samples = wavfile.read(data_path + \"/\" + label + \"/\" + file)\n",
    "        duration = float(len(samples)/SAMPLING_RATE)\n",
    "                \n",
    "        if duration < 1: samples = pad_audio(samples)\n",
    "            \n",
    "        if (label + \"/\" + file) in validation_list: \n",
    "            val_labels.append(label)\n",
    "            val_specgrams.append(specgram(samples, SAMPLING_RATE))\n",
    "        elif (label + \"/\" + file) in testing_list: \n",
    "            test_labels.append(label)\n",
    "            test_specgrams.append(specgram(samples, SAMPLING_RATE))\n",
    "        else:\n",
    "            train_labels.append(label)\n",
    "            train_specgrams.append(specgram(samples, SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aff870",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> 1.3. Data labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a960c2e",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 1.3.1. Noise-free data split (for hyperparameters tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a049be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:02.736765Z",
     "start_time": "2022-05-03T19:47:00.608443Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_specgrams)\n",
    "X_val = np.array(val_specgrams)\n",
    "X_test = np.array(test_specgrams)\n",
    "\n",
    "Y_train = assign_unknown_label(train_labels)\n",
    "Y_val = assign_unknown_label(val_labels)\n",
    "Y_test = assign_unknown_label(test_labels)\n",
    "\n",
    "Y_train = np.array(encode_labels(Y_train).values)\n",
    "Y_val = np.array(encode_labels(Y_val).values)\n",
    "Y_test = np.array(encode_labels(Y_test).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68893e",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 1.3.2. Approach 1 - taking `background_noise` observations as separate `silence` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0360d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:02.836828Z",
     "start_time": "2022-05-03T19:47:02.736765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split noise into 3 disjoint subsets (train, valid & test sets)\n",
    "N = 64721\n",
    "valid_ratio = np.round(len(validation_list)/N, 2)\n",
    "test_ratio = np.round(len(testing_list)/N, 2)\n",
    "train_ratio = 1 - (valid_ratio+test_ratio)\n",
    "\n",
    "sets_list = [\"train\", \"val\", \"test\"]\n",
    "obs_split = np.array(random.choices(sets_list, weights=(train_ratio, valid_ratio, test_ratio), k=N))\n",
    "train_mask, val_mask, test_mask = obs_split == \"train\", obs_split == \"val\", obs_split == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3001513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:02.853091Z",
     "start_time": "2022-05-03T19:47:02.836828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations assigned to train set: 303\n",
      "Number of observations assigned to validation set: 48\n",
      "Number of observations assigned to test set: 51\n"
     ]
    }
   ],
   "source": [
    "train_noise = list(compress(one_sec_background_noise_specgrams, train_mask))\n",
    "print(f'Number of observations assigned to train set: {len(train_noise)}')\n",
    "\n",
    "val_noise = list(compress(one_sec_background_noise_specgrams, val_mask))\n",
    "print(f'Number of observations assigned to validation set: {len(val_noise)}')\n",
    "\n",
    "test_noise = list(compress(one_sec_background_noise_specgrams, test_mask))\n",
    "print(f'Number of observations assigned to test set: {len(test_noise)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc35b15d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:02.878816Z",
     "start_time": "2022-05-03T19:47:02.856082Z"
    }
   },
   "outputs": [],
   "source": [
    "train_specgrams_1 = train_specgrams + train_noise\n",
    "train_labels_1 = train_labels + ['silence' for i in range(len(train_noise))]\n",
    "\n",
    "val_specgrams_1 = val_specgrams + val_noise\n",
    "val_labels_1 = val_labels + ['silence' for i in range(len(val_noise))]\n",
    "\n",
    "test_specgrams_1 = test_specgrams + test_noise\n",
    "test_labels_1 = test_labels + ['silence' for i in range(len(test_noise))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b75257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:33.027251Z",
     "start_time": "2022-05-03T19:47:02.878816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51391, 99, 161)\n",
      "(6846, 99, 161)\n",
      "(6886, 99, 161)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(train_specgrams_1)\n",
    "print(x_train_1.shape)\n",
    "\n",
    "x_val_1 = np.array(val_specgrams_1)\n",
    "print(x_val_1.shape)\n",
    "\n",
    "x_test_1 = np.array(test_specgrams_1)\n",
    "print(x_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86b225be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:34.102375Z",
     "start_time": "2022-05-03T19:47:33.048198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n",
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n",
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "classes=CLASSES+['silence']\n",
    "\n",
    "y_train_1 = assign_unknown_label(train_labels_1, classes=classes)\n",
    "print(np.unique(y_train_1))\n",
    "\n",
    "y_val_1 = assign_unknown_label(val_labels_1, classes=classes)\n",
    "print(np.unique(y_val_1))\n",
    "\n",
    "y_test_1 = assign_unknown_label(test_labels_1, classes=classes)\n",
    "print(np.unique(y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe4f9ab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:36.867031Z",
     "start_time": "2022-05-03T19:47:34.112348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_specgrams_1, val_specgrams_1, test_specgrams_1\n",
    "del train_labels_1, val_labels_1, test_labels_1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049945e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:37.030910Z",
     "start_time": "2022-05-03T19:47:36.867031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Labels encoding\n",
    "y_train_1 = np.array(encode_labels(y_train_1).values)\n",
    "y_val_1 = np.array(encode_labels(y_val_1).values)\n",
    "y_test_1 = np.array(encode_labels(y_test_1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703d383",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 1.3.2. Approach 2 - noising the training subset(s) with the 'background_noise' class observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2edab460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:37.361667Z",
     "start_time": "2022-05-03T19:47:37.038890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_cnt</th>\n",
       "      <th>noise_cnt</th>\n",
       "      <th>noise_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1892</td>\n",
       "      <td>186</td>\n",
       "      <td>0.098309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>1885</td>\n",
       "      <td>177</td>\n",
       "      <td>0.093899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seven</th>\n",
       "      <td>1875</td>\n",
       "      <td>190</td>\n",
       "      <td>0.101333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nine</th>\n",
       "      <td>1875</td>\n",
       "      <td>204</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1873</td>\n",
       "      <td>218</td>\n",
       "      <td>0.116391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>1866</td>\n",
       "      <td>195</td>\n",
       "      <td>0.104502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1864</td>\n",
       "      <td>191</td>\n",
       "      <td>0.102468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>1863</td>\n",
       "      <td>195</td>\n",
       "      <td>0.104670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>1861</td>\n",
       "      <td>206</td>\n",
       "      <td>0.110693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>1860</td>\n",
       "      <td>183</td>\n",
       "      <td>0.098387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>1853</td>\n",
       "      <td>204</td>\n",
       "      <td>0.110092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1852</td>\n",
       "      <td>188</td>\n",
       "      <td>0.101512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eight</th>\n",
       "      <td>1852</td>\n",
       "      <td>187</td>\n",
       "      <td>0.100972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>1844</td>\n",
       "      <td>172</td>\n",
       "      <td>0.093275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>1843</td>\n",
       "      <td>161</td>\n",
       "      <td>0.087358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down</th>\n",
       "      <td>1842</td>\n",
       "      <td>167</td>\n",
       "      <td>0.090662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>1841</td>\n",
       "      <td>175</td>\n",
       "      <td>0.095057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>1839</td>\n",
       "      <td>168</td>\n",
       "      <td>0.091354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>1839</td>\n",
       "      <td>173</td>\n",
       "      <td>0.094073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>1839</td>\n",
       "      <td>160</td>\n",
       "      <td>0.087004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1427</td>\n",
       "      <td>148</td>\n",
       "      <td>0.103714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marvin</th>\n",
       "      <td>1424</td>\n",
       "      <td>155</td>\n",
       "      <td>0.108848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>1414</td>\n",
       "      <td>150</td>\n",
       "      <td>0.106082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>1411</td>\n",
       "      <td>147</td>\n",
       "      <td>0.104181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1399</td>\n",
       "      <td>156</td>\n",
       "      <td>0.111508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1396</td>\n",
       "      <td>111</td>\n",
       "      <td>0.079513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1374</td>\n",
       "      <td>148</td>\n",
       "      <td>0.107715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>1373</td>\n",
       "      <td>124</td>\n",
       "      <td>0.090313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheila</th>\n",
       "      <td>1372</td>\n",
       "      <td>134</td>\n",
       "      <td>0.097668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed</th>\n",
       "      <td>1340</td>\n",
       "      <td>135</td>\n",
       "      <td>0.100746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        obs_cnt  noise_cnt  noise_ratio\n",
       "one        1892        186     0.098309\n",
       "stop       1885        177     0.093899\n",
       "seven      1875        190     0.101333\n",
       "nine       1875        204     0.108800\n",
       "two        1873        218     0.116391\n",
       "zero       1866        195     0.104502\n",
       "on         1864        191     0.102468\n",
       "six        1863        195     0.104670\n",
       "go         1861        206     0.110693\n",
       "yes        1860        183     0.098387\n",
       "no         1853        204     0.110092\n",
       "right      1852        188     0.101512\n",
       "eight      1852        187     0.100972\n",
       "five       1844        172     0.093275\n",
       "up         1843        161     0.087358\n",
       "down       1842        167     0.090662\n",
       "three      1841        175     0.095057\n",
       "left       1839        168     0.091354\n",
       "off        1839        173     0.094073\n",
       "four       1839        160     0.087004\n",
       "house      1427        148     0.103714\n",
       "marvin     1424        155     0.108848\n",
       "wow        1414        150     0.106082\n",
       "bird       1411        147     0.104181\n",
       "cat        1399        156     0.111508\n",
       "dog        1396        111     0.079513\n",
       "tree       1374        148     0.107715\n",
       "happy      1373        124     0.090313\n",
       "sheila     1372        134     0.097668\n",
       "bed        1340        135     0.100746"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_summary = pd.Series(train_labels).value_counts()\n",
    "n = math.floor(NOISE_RATIO*train_labels_summary.sum())\n",
    "noised_labels = random.choices(train_labels, k=n)\n",
    "\n",
    "summary = pd.DataFrame(train_labels_summary, columns=[\"obs_cnt\"])\n",
    "summary[\"noise_cnt\"] = pd.Series(noised_labels).value_counts()\n",
    "summary[\"noise_ratio\"] = summary[\"noise_cnt\"] / summary[\"obs_cnt\"]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5527ab01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:47:37.392908Z",
     "start_time": "2022-05-03T19:47:37.361667Z"
    }
   },
   "outputs": [],
   "source": [
    "train_specgrams_2 = train_specgrams + random.choices(one_sec_background_noise_specgrams, k=n)\n",
    "train_labels_2 = train_labels + noised_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb0baf74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:07.364291Z",
     "start_time": "2022-05-03T19:47:37.392908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56196, 99, 161)\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = np.array(train_specgrams_2)\n",
    "print(x_train_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2075ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:09.523031Z",
     "start_time": "2022-05-03T19:48:07.642063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'unknown' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "y_train_2 = assign_unknown_label(train_labels_2)\n",
    "print(np.unique(y_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff4eb1e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:10.368794Z",
     "start_time": "2022-05-03T19:48:09.528017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Labels encoding\n",
    "y_train_2 = np.array(encode_labels(y_train_2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36a2eb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:29.414546Z",
     "start_time": "2022-05-03T19:48:10.370168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_specgrams_2, train_labels_2\n",
    "del train_specgrams, val_specgrams, test_specgrams\n",
    "del train_labels, val_labels, test_labels\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305a760",
   "metadata": {},
   "source": [
    "# <span style='font-family:Georgia'> 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03900c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:29.429982Z",
     "start_time": "2022-05-03T19:48:29.414546Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_DELTA=1e-3\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0f192",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> 2.1. Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875e17b",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 2.1.1. Learning rate & batch size tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f534ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:29.468040Z",
     "start_time": "2022-05-03T19:48:29.430979Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters set-up\n",
    "INPUT_DIM = (X_train.shape[1], X_train.shape[2])\n",
    "OUTPUT_DIM = Y_train.shape[1]\n",
    "\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "ITER = 10\n",
    "EPOCHS = 50\n",
    "PATIENCE=int(EPOCHS/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fc8da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:29.484843Z",
     "start_time": "2022-05-03T19:48:29.468785Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = [1e-5, 1e-4, 1e-3]\n",
    "batch_size = [128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d0cbf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T19:48:29.501497Z",
     "start_time": "2022-05-03T19:48:29.485448Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, min_delta=MIN_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfde49c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-03T19:19:08.294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b458c7ef00284552ba03847836542b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27ef2e45234a94bdcaea93270583b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861398bc943d469fbe571cab21ef1f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 09:19:08.410043: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-05 09:19:08.410069: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-05 09:19:08.410088: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (agatamakarewicz-Legion-Y540-15IRH): /proc/driver/nvidia/version does not exist\n",
      "2022-05-05 09:19:08.410826: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 09:19:08.571375: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3257166528 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 17s 39ms/step - loss: 1.8191 - accuracy: 0.5359 - val_loss: 1.5783 - val_accuracy: 0.6209\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.5874 - accuracy: 0.6298 - val_loss: 1.5077 - val_accuracy: 0.6199\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.5294 - accuracy: 0.6313 - val_loss: 1.4615 - val_accuracy: 0.6186\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 1.4860 - accuracy: 0.6322 - val_loss: 1.4356 - val_accuracy: 0.6192\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.4489 - accuracy: 0.6323 - val_loss: 1.4057 - val_accuracy: 0.6187\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.4143 - accuracy: 0.6311 - val_loss: 1.3674 - val_accuracy: 0.6202\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 09:20:44.076668: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3257166528 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 25s 58ms/step - loss: 1.4494 - accuracy: 0.6239 - val_loss: 1.3007 - val_accuracy: 0.6258\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 1.2689 - accuracy: 0.6378 - val_loss: 1.1866 - val_accuracy: 0.6337\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: 1.1763 - accuracy: 0.6473 - val_loss: 1.0750 - val_accuracy: 0.6534\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 24s 59ms/step - loss: 1.1076 - accuracy: 0.6604 - val_loss: 1.0107 - val_accuracy: 0.6711\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 1.0502 - accuracy: 0.6730 - val_loss: 0.9363 - val_accuracy: 0.6915\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: 0.9962 - accuracy: 0.6848 - val_loss: 0.8760 - val_accuracy: 0.7139\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.9508 - accuracy: 0.6980 - val_loss: 0.8321 - val_accuracy: 0.7336\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.9072 - accuracy: 0.7101 - val_loss: 0.7822 - val_accuracy: 0.7535\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.8691 - accuracy: 0.7211 - val_loss: 0.7564 - val_accuracy: 0.7621\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.8350 - accuracy: 0.7317 - val_loss: 0.7225 - val_accuracy: 0.7727\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.7996 - accuracy: 0.7423 - val_loss: 0.7069 - val_accuracy: 0.7745\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.7753 - accuracy: 0.7478 - val_loss: 0.6699 - val_accuracy: 0.7882\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.7460 - accuracy: 0.7609 - val_loss: 0.6483 - val_accuracy: 0.7973\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.7203 - accuracy: 0.7685 - val_loss: 0.6251 - val_accuracy: 0.8014\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.6974 - accuracy: 0.7749 - val_loss: 0.6059 - val_accuracy: 0.8133\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.6780 - accuracy: 0.7816 - val_loss: 0.5927 - val_accuracy: 0.8186\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.6534 - accuracy: 0.7900 - val_loss: 0.5628 - val_accuracy: 0.8252\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 23s 58ms/step - loss: 0.6367 - accuracy: 0.7939 - val_loss: 0.5588 - val_accuracy: 0.8314\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.6199 - accuracy: 0.8002 - val_loss: 0.5415 - val_accuracy: 0.8358\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5996 - accuracy: 0.8058 - val_loss: 0.5330 - val_accuracy: 0.8414\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5822 - accuracy: 0.8118 - val_loss: 0.5174 - val_accuracy: 0.8448\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.5692 - accuracy: 0.8165 - val_loss: 0.5043 - val_accuracy: 0.8494\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5536 - accuracy: 0.8224 - val_loss: 0.4936 - val_accuracy: 0.8523\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5340 - accuracy: 0.8286 - val_loss: 0.4758 - val_accuracy: 0.8594\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5243 - accuracy: 0.8321 - val_loss: 0.4748 - val_accuracy: 0.8570\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.5112 - accuracy: 0.8373 - val_loss: 0.4646 - val_accuracy: 0.8613\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.5028 - accuracy: 0.8394 - val_loss: 0.4592 - val_accuracy: 0.8628\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4865 - accuracy: 0.8462 - val_loss: 0.4529 - val_accuracy: 0.8641\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4761 - accuracy: 0.8490 - val_loss: 0.4490 - val_accuracy: 0.8641\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4620 - accuracy: 0.8532 - val_loss: 0.4557 - val_accuracy: 0.8679\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4559 - accuracy: 0.8566 - val_loss: 0.4372 - val_accuracy: 0.8710\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.4482 - accuracy: 0.8578 - val_loss: 0.4266 - val_accuracy: 0.8744\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4394 - accuracy: 0.8612 - val_loss: 0.4228 - val_accuracy: 0.8753\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4302 - accuracy: 0.8652 - val_loss: 0.4233 - val_accuracy: 0.8772\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4216 - accuracy: 0.8658 - val_loss: 0.4068 - val_accuracy: 0.8779\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.4091 - accuracy: 0.8695 - val_loss: 0.3970 - val_accuracy: 0.8807\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.4078 - accuracy: 0.8700 - val_loss: 0.4014 - val_accuracy: 0.8788\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3967 - accuracy: 0.8745 - val_loss: 0.3988 - val_accuracy: 0.8820\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3903 - accuracy: 0.8774 - val_loss: 0.4038 - val_accuracy: 0.8786\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3815 - accuracy: 0.8797 - val_loss: 0.3890 - val_accuracy: 0.8835\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3768 - accuracy: 0.8811 - val_loss: 0.3898 - val_accuracy: 0.8842\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 0.3679 - accuracy: 0.8828 - val_loss: 0.3918 - val_accuracy: 0.8842\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3637 - accuracy: 0.8863 - val_loss: 0.3695 - val_accuracy: 0.8892\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3564 - accuracy: 0.8876 - val_loss: 0.3745 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3515 - accuracy: 0.8873 - val_loss: 0.3764 - val_accuracy: 0.8894\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 24s 60ms/step - loss: 0.3459 - accuracy: 0.8913 - val_loss: 0.3603 - val_accuracy: 0.8913\n",
      "Epoch 47/50\n",
      "101/400 [======>.......................] - ETA: 17s - loss: 0.3478 - accuracy: 0.8871"
     ]
    }
   ],
   "source": [
    "model1_acc_all, model2_acc_all, model3_acc_all = [], [], []\n",
    "\n",
    "for lr in tqdm(learning_rate):\n",
    "    model1_acc_lr, model2_acc_lr, model3_acc_lr = [], [], []\n",
    "    \n",
    "    for size in tqdm(batch_size):\n",
    "        model1_acc_bs, model2_acc_bs, model3_acc_bs = [], [], []        \n",
    "    \n",
    "        for i in tqdm(range(ITER)):\n",
    "            OPT = Adam(learning_rate=lr, clipnorm=1.0)\n",
    "            # SimpleRNN\n",
    "            model1 = rnn_network(INPUT_DIM, OUTPUT_DIM, SimpleRNN, OPT)\n",
    "            K.clear_session()\n",
    "            model1_history = model1.fit(X_train, Y_train,\n",
    "                                        batch_size=size, epochs=EPOCHS, verbose=1,\n",
    "                                        validation_data=(X_val, Y_val),\n",
    "                                        callbacks=[early_stop]\n",
    "                                       )\n",
    "\n",
    "            # LSTM\n",
    "            model2 = rnn_network(INPUT_DIM, OUTPUT_DIM, LSTM, OPT)\n",
    "            K.clear_session()\n",
    "            model2_history = model2.fit(X_train, Y_train,\n",
    "                                        batch_size=size, epochs=EPOCHS, verbose=1,\n",
    "                                        validation_data=(X_val, Y_val),\n",
    "                                        callbacks=[early_stop]\n",
    "                                       )\n",
    "\n",
    "            # GRU\n",
    "            model3 = rnn_network(INPUT_DIM, OUTPUT_DIM, GRU, OPT)\n",
    "            K.clear_session()\n",
    "            model3_history = model3.fit(X_train, Y_train,\n",
    "                                        batch_size=size, epochs=EPOCHS, verbose=1,\n",
    "                                        validation_data=(X_val, Y_val),\n",
    "                                        callbacks=[early_stop]\n",
    "                                       )\n",
    "            \n",
    "            # Save models predictions accuracies for each iteration\n",
    "            y_pred_1 = model1.predict(X_test)\n",
    "            y_pred_2 = model2.predict(X_test)\n",
    "            y_pred_3 = model3.predict(X_test)\n",
    "            y_pred_classes_1 = np.argmax(y_pred_1, axis=-1)\n",
    "            y_pred_classes_2 = np.argmax(y_pred_2, axis=-1)\n",
    "            y_pred_classes_3 = np.argmax(y_pred_3, axis=-1)\n",
    "\n",
    "            model1_acc_bs.append(accuracy_score(Y_test_classes, y_pred_classes_1))\n",
    "            model2_acc_bs.append(accuracy_score(Y_test_classes, y_pred_classes_2))\n",
    "            model3_acc_bs.append(accuracy_score(Y_test_classes, y_pred_classes_3))\n",
    "\n",
    "        model1_acc_lr.append(model1_acc_bs)\n",
    "        model2_acc_lr.append(model2_acc_bs)\n",
    "        model3_acc_lr.append(model3_acc_bs)\n",
    "        \n",
    "    # Save models results for each learning rate\n",
    "    model1_acc_all.append(model1_acc_lr)\n",
    "    model2_acc_all.append(model2_acc_lr)\n",
    "    model3_acc_all.append(model3_acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e67f0c",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 2.1.2. Tuning results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0a5a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.354535Z",
     "start_time": "2022-05-04T05:28:02.716788Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "model_1_acc_lr, model_2_acc_lr, model_3_acc_lr = [], [], []\n",
    "\n",
    "for i in range(len(learning_rate)):\n",
    "    model_1_acc_bs, model_2_acc_bs, model_3_acc_bs = [], [], []\n",
    "    for j in range(len(batch_size)):\n",
    "        # mean over iterations (mean score for each learning_rate-batch_size pair)\n",
    "        model_1_acc_bs.append(np.mean(model1_acc_all[i][j]))\n",
    "        model_2_acc_bs.append(np.mean(model2_acc_all[i][j]))\n",
    "        model_3_acc_bs.append(np.mean(model3_acc_all[i][j]))\n",
    "        \n",
    "    model_1_acc_lr.append(model_1_acc_bs)\n",
    "    model_2_acc_lr.append(model_2_acc_bs)\n",
    "    model_3_acc_lr.append(model_3_acc_bs)\n",
    "        \n",
    "    # mean over batch_sized (mean score for each learning_rate)\n",
    "    acc_all.append([\n",
    "        np.mean(model_1_acc_lr),\n",
    "        np.mean(model_2_acc_lr),\n",
    "        np.mean(model_3_acc_lr)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15436b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.358494Z",
     "start_time": "2022-05-03T19:19:23.554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy depending on both: Learning rate & Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1afc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.360489Z",
     "start_time": "2022-05-03T19:19:23.943Z"
    }
   },
   "outputs": [],
   "source": [
    "models_results = [\n",
    "    pd.DataFrame(model_1_acc_lr, columns=batch_size, index=learning_rate),\n",
    "    pd.DataFrame(model_2_acc_lr, columns=batch_size, index=learning_rate),\n",
    "    pd.DataFrame(model_3_acc_lr, columns=batch_size, index=learning_rate)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9598f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.361487Z",
     "start_time": "2022-05-03T19:19:25.455Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_heatmaps(models_results, title=\"Hyperparameters tuning results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59537ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.362487Z",
     "start_time": "2022-05-03T19:19:26.583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy depending on both: Learning rate (mean over batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1b9f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.363484Z",
     "start_time": "2022-05-03T19:19:26.931Z"
    }
   },
   "outputs": [],
   "source": [
    "results_acc = pd.DataFrame(acc_all)\n",
    "results_acc.columns = ['SimpleRNN', 'LSTM', 'GRU']\n",
    "results_acc.index = learning_rate\n",
    "results_acc.index.name = \"Learning rate\"\n",
    "results_acc_melted = pd.melt(results_acc.reset_index(), id_vars=['Learning rate'], value_vars=['SimpleRNN', 'LSTM', 'GRU'])\n",
    "results_acc_melted.columns=['Learning rate', 'Model', 'Accuracy']\n",
    "results_acc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24649530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:28:15.365479Z",
     "start_time": "2022-05-03T19:19:27.279Z"
    }
   },
   "outputs": [],
   "source": [
    "for j in range(results_acc_melted.shape[0]):\n",
    "    results_acc_melted.loc[j, 'Learning rate'] = '{:.0e}'.format(results_acc_melted.loc[j, 'Learning rate'])\n",
    "sns.stripplot(x=\"Learning rate\", y=\"Accuracy\", hue=\"Model\",\n",
    "               data=results_acc_melted, palette=\"Set2\", dodge=False, jitter=0.0)    \n",
    "plt.title(\"Accuracy depending on learning rate\", size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153221a5",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 2.1.3. Tuned models overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf15ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BEFORE BELOW CALCULATIONS: select the best learning rate & batch size pair for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cd5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfd154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T18:10:57.506426Z",
     "start_time": "2022-05-02T17:48:06.066753Z"
    }
   },
   "outputs": [],
   "source": [
    "MODELS = ['SimpleRNN', 'LSTM', 'GRU']\n",
    "LEARNING_RATES = [1e-3, 1e-4, 1e-3]\n",
    "BATCH_SIZES = [128, 128, 128]\n",
    "\n",
    "# SimpleRNN\n",
    "OPT = Adam(learning_rate=LEARNING_RATES[0], clipnorm=1.0)\n",
    "model1 = rnn_network(INPUT_DIM, OUTPUT_DIM, SimpleRNN, OPT)\n",
    "K.clear_session()\n",
    "model1_history = model1.fit(X_train, Y_train,\n",
    "                            batch_size=BATCH_SIZES[0], epochs=EPOCHS, verbose=1,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[early_stop]\n",
    "                           )\n",
    "\n",
    "# LSTM\n",
    "OPT = Adam(learning_rate=LEARNING_RATES[1], clipnorm=1.0)\n",
    "model2 = rnn_network(INPUT_DIM, OUTPUT_DIM, LSTM, OPT)\n",
    "K.clear_session()\n",
    "model2_history = model2.fit(X_train, Y_train,\n",
    "                            batch_size=BATCH_SIZES[1], epochs=EPOCHS, verbose=1,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[early_stop]\n",
    "                           )\n",
    "\n",
    "# GRU\n",
    "OPT = Adam(learning_rate=LEARNING_RATES[2], clipnorm=1.0)\n",
    "model3 = rnn_network(INPUT_DIM, OUTPUT_DIM, GRU, OPT)\n",
    "K.clear_session()\n",
    "model3_history = model3.fit(X_train, Y_train,\n",
    "                            batch_size=BATCH_SIZES[2], epochs=EPOCHS, verbose=1,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[early_stop]\n",
    "                           )\n",
    "\n",
    "# Save models predictions accuracies for each iteration\n",
    "y_pred_1 = model1.predict(X_test)\n",
    "y_pred_2 = model2.predict(X_test)\n",
    "y_pred_3 = model3.predict(X_test)\n",
    "y_pred_classes_1 = np.argmax(y_pred_1, axis=-1)\n",
    "y_pred_classes_2 = np.argmax(y_pred_2, axis=-1)\n",
    "y_pred_classes_3 = np.argmax(y_pred_3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360ae9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T18:10:58.128911Z",
     "start_time": "2022-05-02T18:10:57.511515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convergence analysis\n",
    "models_history = [model1_history, model2_history, model3_history]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(18,6))\n",
    "models = ['1', '2', '3']\n",
    "for i in range(3):\n",
    "    model_name=MODELS[i]\n",
    "    history = models_history[i]\n",
    "    data_lr = history.history['loss']\n",
    "    sns.lineplot(data=data_lr, ax=axes[i])\n",
    "    if i == 0 : axes[i].set_ylim([0,2.5]) # due to huge loss values for 1e-2 (to make other lines visible)\n",
    "    axes[i].set_title('Model '+model_name)\n",
    "    axes[i].set_xlabel('Epoch', size=12)\n",
    "    axes[i].set_ylabel('Loss', size=12)\n",
    "fig.suptitle(\"Convergence analysis\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67439893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T18:11:00.644742Z",
     "start_time": "2022-05-02T18:10:58.130906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models evaluation- confusion matrices\n",
    "models_results = [pd.DataFrame(confusion_matrix(Y_test_classes, y_pred_classes_1)),\n",
    "                  pd.DataFrame(confusion_matrix(Y_test_classes, y_pred_classes_2)),\n",
    "                  pd.DataFrame(confusion_matrix(Y_test_classes, y_pred_classes_3))]\n",
    "\n",
    "plot_confusion_matr(models_results, 'Models evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143daa87",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> 2.2. Noise data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52034972",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 2.2.1. Approach 1 - taking `background_noise` observations as separate `silence` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cb6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T18:11:00.654104Z",
     "start_time": "2022-05-02T18:11:00.646736Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, x_test = x_train_1, x_val_1, x_test_1\n",
    "y_train, y_val, y_test = y_train_1, y_val_1, y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ba142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T19:28:06.404910Z",
     "start_time": "2022-05-02T19:28:06.399958Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters set-up\n",
    "INPUT_DIM = (x_train.shape[1], x_train.shape[2])\n",
    "OUTPUT_DIM = y_train.shape[1]\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, min_delta=MIN_DELTA)\n",
    "\n",
    "# TODO: Choose best LR & BATCH_SIZE\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "OPT = Adam(learning_rate=LR, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae78ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T20:13:23.958611Z",
     "start_time": "2022-05-02T19:28:07.569577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models training\n",
    "model1_stats = []\n",
    "model1_acc = []\n",
    "model2_stats = []\n",
    "model2_acc = []\n",
    "model3_stats = []\n",
    "model3_acc = []\n",
    "\n",
    "for i in tqdm(range(ITER)):\n",
    "    # SimpleRNN\n",
    "    model1 = rnn_network(INPUT_DIM, OUTPUT_DIM, SimpleRNN, OPT)\n",
    "    K.clear_session()\n",
    "    model1_history = model1.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # LSTM\n",
    "    model2 = rnn_network(INPUT_DIM, OUTPUT_DIM, LSTM, OPT)\n",
    "    K.clear_session()\n",
    "    model2_history = model2.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # GRU\n",
    "    model3 = rnn_network(INPUT_DIM, OUTPUT_DIM, GRU, OPT)\n",
    "    K.clear_session()\n",
    "    model3_history = model3.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # Saving results\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    model1_stats.append(model1_history)\n",
    "    y_pred_1 = model1.predict(x_test)\n",
    "    y_pred_classes_1 = np.argmax(y_pred_1, axis=-1)\n",
    "    model1_acc.append(accuracy_score(y_test_classes, y_pred_classes_1))\n",
    "\n",
    "    model2_stats.append(model2_history)\n",
    "    y_pred_2 = model2.predict(x_test)\n",
    "    y_pred_classes_2 = np.argmax(y_pred_2, axis=-1)\n",
    "    model2_acc.append(accuracy_score(y_test_classes, y_pred_classes_2))\n",
    "    \n",
    "    model3_stats.append(model3_history)\n",
    "    y_pred_3 = model3.predict(x_test)\n",
    "    y_pred_classes_3 = np.argmax(y_pred_3, axis=-1)\n",
    "    model3_acc.append(accuracy_score(y_test_classes, y_pred_classes_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b8b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T20:13:24.005050Z",
     "start_time": "2022-05-02T20:13:23.960678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models summary\n",
    "approach1_acc_results = pd.DataFrame([model1_acc, model2_acc, model3_acc]).T\n",
    "approach1_acc_results.columns=['SimpleRNN', 'LSTM', 'GRU']\n",
    "approach1_acc_results_stats = approach1_acc_results.describe().T[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aaded6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T20:13:24.034348Z",
     "start_time": "2022-05-02T20:13:24.008561Z"
    }
   },
   "outputs": [],
   "source": [
    "model1_epochs = []\n",
    "model2_epochs = []\n",
    "model3_epochs = []\n",
    "for i in range(ITER):\n",
    "    model1_epochs.append(len(model1_stats[i].history['loss']))\n",
    "    model2_epochs.append(len(model2_stats[i].history['loss']))\n",
    "    model3_epochs.append(len(model3_stats[i].history['loss']))\n",
    "    \n",
    "approach1_acc_results_stats['epochs'] = [np.array(model1_epochs).mean(), np.array(model2_epochs).mean(),\n",
    "                                      np.array(model3_epochs).mean()]\n",
    "approach1_acc_results_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72095d57",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> 2.2.2. Approach 2 - noising the training subset(s) with the `background_noise` class observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bf8fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T20:13:24.049735Z",
     "start_time": "2022-05-02T20:13:24.034348Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, x_test = x_train_2, X_val, X_test\n",
    "y_train, y_val, y_test = y_train_2, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b2c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T20:13:24.065694Z",
     "start_time": "2022-05-02T20:13:24.052729Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters set-up\n",
    "INPUT_DIM = (x_train.shape[1], x_train.shape[2])\n",
    "OUTPUT_DIM = y_train.shape[1]\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, min_delta=MIN_DELTA)\n",
    "\n",
    "# TODO: Choose best LR & BATCH_SIZE\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "OPT = Adam(learning_rate=LR, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a39295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:05:02.607788Z",
     "start_time": "2022-05-02T20:13:24.068684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models training\n",
    "model4_stats = []\n",
    "model4_acc = []\n",
    "model5_stats = []\n",
    "model5_acc = []\n",
    "model6_stats = []\n",
    "model6_acc = []\n",
    "\n",
    "for i in tqdm(range(ITER)):\n",
    "    # SimpleRNN\n",
    "    model4 = rnn_network(INPUT_DIM, OUTPUT_DIM, SimpleRNN, OPT)\n",
    "    K.clear_session()\n",
    "    model4_history = model4.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # LSTM\n",
    "    model5 = rnn_network(INPUT_DIM, OUTPUT_DIM, LSTM, OPT)\n",
    "    K.clear_session()\n",
    "    \n",
    "    model5_history = model5.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # GRU\n",
    "    model6 = rnn_network(INPUT_DIM, OUTPUT_DIM, GRU, OPT)\n",
    "    K.clear_session()\n",
    "    model6_history = model6.fit(x_train, y_train,\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[early_stop]\n",
    "                               )\n",
    "    \n",
    "    # Saving results\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    model4_stats.append(model4_history)\n",
    "    y_pred_4 = model4.predict(x_test)\n",
    "    y_pred_classes_4 = np.argmax(y_pred_4, axis=-1)\n",
    "    model4_acc.append(accuracy_score(y_test_classes, y_pred_classes_4))\n",
    "\n",
    "    model5_stats.append(model5_history)\n",
    "    y_pred_5 = model5.predict(x_test)\n",
    "    y_pred_classes_5 = np.argmax(y_pred_5, axis=-1)\n",
    "    model5_acc.append(accuracy_score(y_test_classes, y_pred_classes_5))\n",
    "    \n",
    "    model6_stats.append(model6_history)\n",
    "    y_pred_6 = model6.predict(x_test)\n",
    "    y_pred_classes_6 = np.argmax(y_pred_6, axis=-1)\n",
    "    model6_acc.append(accuracy_score(y_test_classes, y_pred_classes_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2ffb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:05:02.696500Z",
     "start_time": "2022-05-02T21:05:02.612806Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models summary\n",
    "approach2_acc_results = pd.DataFrame([model4_acc, model5_acc, model6_acc]).T\n",
    "approach2_acc_results.columns=['SimpleRNN', 'LSTM', 'GRU']\n",
    "approach2_acc_results_stats = approach2_acc_results.describe().T[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a9f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T21:05:02.733475Z",
     "start_time": "2022-05-02T21:05:02.699492Z"
    }
   },
   "outputs": [],
   "source": [
    "model4_epochs = []\n",
    "model5_epochs = []\n",
    "model6_epochs = []\n",
    "for i in range(ITER):\n",
    "    model4_epochs.append(len(model4_stats[i].history['loss']))\n",
    "    model5_epochs.append(len(model5_stats[i].history['loss']))\n",
    "    model6_epochs.append(len(model6_stats[i].history['loss']))\n",
    "    \n",
    "approach2_acc_results_stats['epochs'] = [np.array(model4_epochs).mean(), np.array(model5_epochs).mean(),\n",
    "                                      np.array(model6_epochs).mean()]\n",
    "approach2_acc_results_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2240dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
